## Data Preprocess

#### Organization of the folder
```
1. count_data.py - Counts the number of data points in the processed files.  
2. extractor.py - Simply extracts the text part of the raw data.
3. java_code_cleaner.py - Converts the extracted text from markup language to pure text format.
4. pages_cleaner.py - Cleans the pages for which scores aren't generated.
5. parser.py - Converts the raw data form to the required format
```

#### Requirements
1. nltk
2. numpy
3. tqdm
4. difflib
5. fuzzyset
6. Levenshtein
7. fuzzywuzzy
8. argparse

#### Extractor

Input is the raw xml file. 
Extracts the text part of the xml file and saves to the output_filename(output_filename can be removed at the end)
To run 
```
python3 extractor.py <xml filename> <output_filename>
```

#### Java Code Cleaner

Input is the file that is stored in the Extractor step. 
Converts the markup language text to pure text(without links, brackets, formats etc.)
A temporay file needs to be given as input argument where the cleaned text is stored. 
To run 
```
python3 java_code_cleaner.py <text_extracted_file> <output_file>
```

#### Parser

Input is the xml file, the scores file which is generated by using the baseline scripts, cleaned version of the page which is the output of the previous step. 
Converts the raw xml format to the sentence wise changes which is the final required format to all the codes. 
To run
```
python parser.py <xml filename> <temporary file to store some data(can be removed)> <scores file> <cleaned verion of page(output of java_cleaner.py)> <final output file>
```

#### Count Data

A helper function that counts the number of data points in the processed files
Can be run on a whole folder or a single file. 
csv file is an optional argument to store the information of the number of datapoints in each file of the folder.
```
usage: count_data.py [-h] [--folder FOLDER] [--file FILE] [--csv CSV]

optional arguments:
  -h, --help       show this help message and exit
  --folder FOLDER  folder containing input.txt's
  --file FILE      file containing input.txt
  --csv CSV        file to append the count of data points

```

#### Pages Cleaner

A helper function that cleans the pages for which scores aren't generated.
Input is the folder containing the final processed files and the folder containing the xml pages. 

```
usage: pages_cleaner.py [-h] [--f_scores F_SCORES] [--f_pages F_PAGES]

optional arguments:
  -h, --help           show this help message and exit
  --f_scores F_SCORES  Floder containing .scores.txt files
  --f_pages F_PAGES    Folder containing xml pages 
```

#### Other scripts

All the files needs to have the line in the header file as the first line in the xml file 
1. add_header_footer - adds the header and footer lines present in the respective files to the files. Run using ./add_header_footer.sh <folder_name> or ./add_header_footer.sh <xml_file_name> (for single file).
2. merger.sh - simply merges all the files in a folder to a single file. The files to be combined shouldn't have the header file line at the top of them.

#### Running the codes

1. Compute the scores using the compute_quality in the scripts folder. (Follow the [interrank](https://github.com/lca4/interank) link to install the necessary libraries and running the scripts)
2. Run the extractor on the file
3. Run the java_code_cleaner on the generated file
4. Run the parser on the generated file
5. To run on the files in a directory, ./data_gen.sh <folder_name>